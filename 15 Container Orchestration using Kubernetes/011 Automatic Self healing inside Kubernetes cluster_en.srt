1
00:00:00,000 --> 00:00:05,000
As of now, we deployed all our microservices into Kubernetes cluster.

2
00:00:05,000 --> 00:00:12,000
As a next step inside this lecture, I'm going to show you the self-healing capability of Kubernetes,

3
00:00:12,000 --> 00:00:19,000
which means whenever Kubernetes is seeing that a specific container is not working properly or it is

4
00:00:19,000 --> 00:00:26,000
completely down, then immediately, Kubernetes will try to self heal the container by recreating a

5
00:00:26,000 --> 00:00:29,000
new container in the place of defective container.

6
00:00:29,000 --> 00:00:34,000
So I'm going to show you the demo of self-healing inside this lecture for the same let me go to the

7
00:00:34,000 --> 00:00:36,000
terminal. Inside my terminal,

8
00:00:36,000 --> 00:00:43,000
first I want to execute a command which is kubectl get replicaset.

9
00:00:43,000 --> 00:00:48,000
We all know inside the deployment instructions we have defined how many replicas we want to maintain

10
00:00:48,000 --> 00:00:49,000
for our containers.

11
00:00:49,000 --> 00:00:54,000
You can quickly check here inside all the manifest files that we have created.

12
00:00:54,000 --> 00:00:59,000
We have mentioned the replicas as one, the same replica information

13
00:00:59,000 --> 00:01:04,000
we can try to see by running this command, which is kubectl get replicaset.

14
00:01:04,000 --> 00:01:10,000
So let me run this command and you should be able to see replica sets for all your deployments, like

15
00:01:10,000 --> 00:01:16,000
for accounts, cards, config server, Eureka server, Gateway server, keycloak and loans. Against each

16
00:01:16,000 --> 00:01:17,000
of the replicaset,

17
00:01:17,000 --> 00:01:23,000
there is a desired state and what is the current state and how many containers are ready to serve to

18
00:01:23,000 --> 00:01:24,000
the client applications.

19
00:01:24,000 --> 00:01:31,000
So based upon this replica set, always my Kubernetes will try to maintain desired number of containers.

20
00:01:31,000 --> 00:01:38,000
If you can go and execute the command, which is kubectl get pods like you can see here, there is a

21
00:01:38,000 --> 00:01:43,000
single pod for each of my deployment because my desired replica is two.

22
00:01:43,000 --> 00:01:50,000
Now, as a next step, I can try to increase the number of replicas for accounts microservice and I'll

23
00:01:50,000 --> 00:01:51,000
show you what is going to happen.

24
00:01:51,000 --> 00:01:58,000
So to increase the replicas, we just have to go to the accounts.yaml and in the place of replicas

25
00:01:58,000 --> 00:02:00,000
we have to mention value to post that

26
00:02:00,000 --> 00:02:02,000
I'm going to save this file.

27
00:02:02,000 --> 00:02:10,000
Now here I'll try to run the command which is kubectl apply -f 5_accounts.yaml.

28
00:02:10,000 --> 00:02:16,000
So as soon as I tried to run this command, my Kubernetes is smart enough to detect the changes right

29
00:02:16,000 --> 00:02:18,000
now that I have made in the Yaml file.

30
00:02:18,000 --> 00:02:25,000
Now if I go and run the get replica set command this time for accounts deployment, you should be able

31
00:02:25,000 --> 00:02:29,000
to see the desired as two and current is two and the ready also two.

32
00:02:29,000 --> 00:02:34,000
We can also confirm the same by running the command which is kubectl get pods and there should be two

33
00:02:34,000 --> 00:02:36,000
parts for your accounts microservice.

34
00:02:36,000 --> 00:02:44,000
One is which is created 99 minutes back and the second one is which is created 27 seconds back.

35
00:02:44,000 --> 00:02:51,000
That means the second pod here is the latest pod that is created to match our desired state.

36
00:02:51,000 --> 00:02:58,000
So now the story is all going well as an excerpt to show you the self-healing capability of Kubernetes,

37
00:02:58,000 --> 00:03:05,000
I'm going to delete the one of the pod of accounts microservice manually, and with that, my desired

38
00:03:05,000 --> 00:03:08,000
status will not match with the current status.

39
00:03:08,000 --> 00:03:14,000
So what Kubernetes will do behind the scenes, it will try to create a new accounts microservice instance.

40
00:03:14,000 --> 00:03:16,000
So all these steps we can see in the demo.

41
00:03:16,000 --> 00:03:23,000
So before that, let me clean the console and I'll try to run the command, which is kubectl, get pods

42
00:03:23,000 --> 00:03:25,000
and post that to delete the pod,

43
00:03:25,000 --> 00:03:31,000
the command that I need to run is, Kubectl delete pod and what is a pod name.

44
00:03:31,000 --> 00:03:34,000
So I'm going to delete the new pod that got created.

45
00:03:34,000 --> 00:03:40,000
So let me copy this pod name and mention the same here and post that I'm going to run this command.

46
00:03:40,000 --> 00:03:43,000
Like you can see now my pod is deleted.

47
00:03:43,000 --> 00:03:47,000
Now let me go and see what is happening in the get replicaset.

48
00:03:47,000 --> 00:03:54,000
So the replicaset is right now is showing the current value as two. Because behind the scenes now if

49
00:03:54,000 --> 00:03:59,000
I try to run the get pods, a new part might have created automatically.

50
00:03:59,000 --> 00:04:05,000
You can see just 20s before a new pod of accounts microservice is created.

51
00:04:05,000 --> 00:04:12,000
That means my Kubernetes always putting the efforts to match my desired state with the current state.

52
00:04:12,000 --> 00:04:14,000
So this is the beauty of Kubernetes.

53
00:04:14,000 --> 00:04:19,000
We can't achieve this self-healing capability with Docker or Docker Compose.

54
00:04:19,000 --> 00:04:25,000
That's why we should always look for container orchestration products like Kubernetes.

55
00:04:25,000 --> 00:04:30,000
So these products, they will always keep an eye on the running containers.

56
00:04:30,000 --> 00:04:37,000
And if any of the container has some health issues, they always going to take an action to make your

57
00:04:37,000 --> 00:04:40,000
desired state and current state matches with each other.

58
00:04:40,000 --> 00:04:45,000
I can also show you what happened behind the scenes whenever we deleted a pod. For the same,

59
00:04:45,000 --> 00:04:51,000
let me clean the console and post that I'm going to run a command which is kubectl get events.

60
00:04:51,000 --> 00:04:57,000
So I want to get all the events happened behind the scenes inside my Kubernetes cluster by sorting all

61
00:04:57,000 --> 00:04:59,000
of them based upon the Create timestamp.

62
00:05:00,000 --> 00:05:02,000
So let me try to execute this command.

63
00:05:02,000 --> 00:05:05,000
So here, let's try to see what are the last two events.

64
00:05:05,000 --> 00:05:09,000
So if you see here, this is the event where I tried to kill my pod.

65
00:05:09,000 --> 00:05:13,000
That's why you are able to see there is a value killing here.

66
00:05:13,000 --> 00:05:20,000
As soon as I killed my pod manually behind the scenes, immediately my Kubernetes tried to create a

67
00:05:20,000 --> 00:05:21,000
new part.

68
00:05:21,000 --> 00:05:25,000
And that's why we're able to see an output as successfully create.

69
00:05:25,000 --> 00:05:29,000
And here also we have a message saying that create pod accounts deployment.

70
00:05:29,000 --> 00:05:35,000
So now you should be able to see all the events properly here because I reduced the font size of my

71
00:05:35,000 --> 00:05:35,000
terminal.

72
00:05:35,000 --> 00:05:38,000
So these are the two events that I'm talking.

73
00:05:38,000 --> 00:05:44,000
This confirms that Kubernetes is capable of self-healing regardless of how many containers and how many

74
00:05:44,000 --> 00:05:47,000
microservices you have inside your Kubernetes cluster.

75
00:05:47,000 --> 00:05:55,000
Your cluster is going to take care of all your containers and make sure they are always running in a

76
00:05:55,000 --> 00:05:56,000
good, healthy status.

77
00:05:56,000 --> 00:05:57,000
I hope you are clear.

78
00:05:57,000 --> 00:05:58,000
Thank you.

79
00:05:58,000 --> 00:06:00,000
And I'll catch you in the next lecture.

80
00:06:00,000 --> 00:06:00,000
Bye.

