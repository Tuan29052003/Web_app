1
00:00:00,000 --> 00:00:07,000
Inside this lecture, let's try to discuss the last five principles or guidelines that we have inside

2
00:00:07,000 --> 00:00:09,000
the 15 factor methodology.

3
00:00:09,000 --> 00:00:13,000
Like you can see here, the next guideline that we have is port binding.

4
00:00:13,000 --> 00:00:20,000
As per this guideline, all the cloud native applications should be self-contained and expose their

5
00:00:20,000 --> 00:00:23,000
services through port binding.

6
00:00:23,000 --> 00:00:30,000
When I say self-contained, an application should not rely on an external server within the execution

7
00:00:30,000 --> 00:00:31,000
environment.

8
00:00:31,000 --> 00:00:37,000
For instance, a traditional Java web application might typically run within a server container like

9
00:00:37,000 --> 00:00:39,000
Tomcat, Jetty or Undertow.

10
00:00:39,000 --> 00:00:44,000
We as a developer should manually deploy our Java code into these servers.

11
00:00:44,000 --> 00:00:50,000
In contrast to this, a cloud native application does not depend on the presence of a Tomcat server

12
00:00:50,000 --> 00:00:52,000
in the environment.

13
00:00:52,000 --> 00:00:55,000
It manages a server as a dependency within itself.

14
00:00:55,000 --> 00:01:01,000
We are already using these inside our microservices, for example using spring boot, we are enabling

15
00:01:01,000 --> 00:01:09,000
the usage of an embedded server where an application incorporate the server within itself instead of

16
00:01:09,000 --> 00:01:12,000
relying on its availability in the execution environment.

17
00:01:12,000 --> 00:01:19,000
Once the application is started using these self-contained server, each application is going to map

18
00:01:19,000 --> 00:01:24,000
to its own server compared to traditional approach where deploying multiple applications in a single

19
00:01:24,000 --> 00:01:25,000
server.

20
00:01:25,000 --> 00:01:30,000
In simple words, we should not deploy multiple applications in a single server.

21
00:01:30,000 --> 00:01:36,000
Instead, every application should be deployed in a separate server and even that server also should

22
00:01:36,000 --> 00:01:39,000
be self-contained but not external to the application.

23
00:01:39,000 --> 00:01:47,000
Once the application is started with its own self-contained server, the applications should expose

24
00:01:47,000 --> 00:01:51,000
its services to the outside world through port binding.

25
00:01:51,000 --> 00:01:56,000
When we are trying to start our Docker image as a Docker container with the help of docker run command,

26
00:01:56,000 --> 00:01:59,000
we use the port forwarding or port mapping.

27
00:01:59,000 --> 00:02:05,000
So using that port binding, we are exposing the microservice to the external network.

28
00:02:05,000 --> 00:02:13,000
Once this application is exposed at a specific port, then any other service or any other clients they

29
00:02:13,000 --> 00:02:20,000
can invoke my microservice and these microservices are cloud native application is going to act as a

30
00:02:20,000 --> 00:02:23,000
backing service for another application.

31
00:02:23,000 --> 00:02:29,000
So this is very common practice within cloud native systems because many applications are many microservices

32
00:02:29,000 --> 00:02:31,000
they want to communicate with each other.

33
00:02:31,000 --> 00:02:39,000
In such scenarios we should make sure we are properly exposing our microservice by following these self-contained

34
00:02:39,000 --> 00:02:41,000
and port binding standards.

35
00:02:41,000 --> 00:02:49,000
Never ever develop cloud native applications, which depends on an external Tomcat server or an external

36
00:02:49,000 --> 00:02:49,000
server.

37
00:02:49,000 --> 00:02:56,000
With such scenarios, you will end up with managing these external servers manually in all the locations

38
00:02:56,000 --> 00:03:01,000
where your cloud native applications and microservices are being deployed.

39
00:03:01,000 --> 00:03:05,000
The next principle that we have here is stateless process.

40
00:03:05,000 --> 00:03:12,000
We know that the cloud native applications are the microservices are developed with high scalability

41
00:03:12,000 --> 00:03:13,000
in mind.

42
00:03:13,000 --> 00:03:20,000
One of these key principles to achieve scalability is to design our applications as stateless process

43
00:03:20,000 --> 00:03:23,000
and adopting a shared nothing architecture.

44
00:03:23,000 --> 00:03:29,000
Like you can see here, there is a single microservice where it has multiple instances running.

45
00:03:29,000 --> 00:03:30,000
To make it more simple.

46
00:03:30,000 --> 00:03:33,000
Let's try to assume you have your accounts microservice.

47
00:03:33,000 --> 00:03:39,000
If it is receiving a lot of traffic, what you will do, you will scale your accounts microservice by

48
00:03:39,000 --> 00:03:43,000
onboarding multiple new instances of same accounts

49
00:03:43,000 --> 00:03:50,000
microservice. So all these multiple instances of accounts, microservice they should follow stateless

50
00:03:50,000 --> 00:03:54,000
process and they should not share anything between themselves.

51
00:03:54,000 --> 00:04:00,000
This is important because when the traffic is low or when an instance is not working properly, we are

52
00:04:00,000 --> 00:04:03,000
going to destroy it or we are going to recreate it.

53
00:04:03,000 --> 00:04:10,000
If the instance of a microservice is going to hold some data, there will be some data loss would occur

54
00:04:10,000 --> 00:04:12,000
and the business logic will be impacted.

55
00:04:12,000 --> 00:04:16,000
That's why our application should be strictly stateless.

56
00:04:16,000 --> 00:04:21,000
However, sometimes there might be a requirement where our accounts microservice or a specific cloud

57
00:04:21,000 --> 00:04:22,000
native service,

58
00:04:22,000 --> 00:04:27,000
it has to store some data or it has to store some user data.

59
00:04:27,000 --> 00:04:31,000
So for all such scenarios, these instances are accounts

60
00:04:31,000 --> 00:04:33,000
microservice or cloud native service,

61
00:04:33,000 --> 00:04:38,000
they should use a backing service like an data store, for example

62
00:04:38,000 --> 00:04:45,000
you can use a database or you can use a redis cache to store all the caching related information.

63
00:04:45,000 --> 00:04:50,000
This will remain your application stateless and whenever they want to store something, they can store

64
00:04:50,000 --> 00:04:53,000
inside the database or any other data store.

65
00:04:53,000 --> 00:04:59,000
Even a particular instance of accounts microservice is shut down and in future, after few minutes

66
00:04:59,000 --> 00:05:00,000
if a new instance

67
00:05:00,000 --> 00:05:01,000
Is coming up,

68
00:05:01,000 --> 00:05:02,000
there is no loss of information.

69
00:05:02,000 --> 00:05:09,000
Everything is stored inside a data store from where my new instance can read and execute the business

70
00:05:09,000 --> 00:05:09,000
logic.

71
00:05:09,000 --> 00:05:15,000
So that's why always make sure you're not storing anything inside your instance, such as user session

72
00:05:15,000 --> 00:05:22,000
related information or caching information, because you're going to lose all that information as soon

73
00:05:22,000 --> 00:05:24,000
as the a particular instance is shut down.

74
00:05:24,000 --> 00:05:30,000
That's why please make sure always every information is being stored inside the storage system and making

75
00:05:30,000 --> 00:05:35,000
your instances and cloud native applications as true stateless applications.

76
00:05:35,000 --> 00:05:40,000
Now let's move on to the next principle that we have, which is concurrency.

77
00:05:40,000 --> 00:05:46,000
We discussed that by implementing stateless applications we can achieve the scalability.

78
00:05:46,000 --> 00:05:51,000
But scalability cannot be achieved solely by creating stateless applications.

79
00:05:51,000 --> 00:05:59,000
While statelessness is important, scalability also requires the ability to serve large number of users.

80
00:05:59,000 --> 00:06:07,000
This means your applications should support concurrent processing to handle multiple users simultaneously.

81
00:06:07,000 --> 00:06:14,000
This means if you have ten different microservice instances are running inside your microservice network,

82
00:06:14,000 --> 00:06:20,000
they should not accept only ten different requests and a process sequentially one by one.

83
00:06:20,000 --> 00:06:27,000
Instead, they should be capable of processing lot of requests parallelly simultaneously to achieve

84
00:06:27,000 --> 00:06:35,000
this, according to the 15 factor methodology process play a very crucial role in application design.

85
00:06:35,000 --> 00:06:40,000
Whenever we are getting more number of traffic, which means we need more number of processes to handle

86
00:06:40,000 --> 00:06:41,000
such traffic.

87
00:06:41,000 --> 00:06:49,000
So in such scenarios we can horizontally scale our processes to distribute the workload across multiple

88
00:06:49,000 --> 00:06:52,000
processors on different machines. Inside Java

89
00:06:52,000 --> 00:06:58,000
we already have this concurrency inbuilt developed when we built our applications with the help of Java

90
00:06:58,000 --> 00:07:05,000
and JVM, concurrency is typically managed by the program itself with the help of multiple threads which

91
00:07:05,000 --> 00:07:07,000
are available from the thread pools.

92
00:07:07,000 --> 00:07:13,000
And whenever you are trying to scale your application, we should never follow the vertical scalability

93
00:07:13,000 --> 00:07:16,000
instead, we should follow the horizontal scalability.

94
00:07:16,000 --> 00:07:23,000
You can see vertical scalability means we are going to increase the Ram memory and CPU processes for

95
00:07:23,000 --> 00:07:23,000
a mission.

96
00:07:23,000 --> 00:07:31,000
To some extent, this vertical scalability may work, but once you reach to a maximum CPU processors

97
00:07:31,000 --> 00:07:36,000
and maximum Ram, then you cannot scale your applications vertically.

98
00:07:36,000 --> 00:07:41,000
That's why we should always follow the horizontal scalability inside the horizontal scalability.

99
00:07:41,000 --> 00:07:48,000
We are going to create multiple virtual machines with the same configurations like two GB Ram and two

100
00:07:48,000 --> 00:07:49,000
CPU.

101
00:07:49,000 --> 00:07:55,000
And inside these virtual machines we can create containers or we can create processes based upon our

102
00:07:55,000 --> 00:07:55,000
requirements.

103
00:07:55,000 --> 00:07:59,000
And there is no limit for our horizontal scalability.

104
00:07:59,000 --> 00:08:05,000
You can create any number of virtual machines and you can deploy any number of containers inside them.

105
00:08:05,000 --> 00:08:12,000
And usually these processes which handles the traffic of the application, they are categorized based

106
00:08:12,000 --> 00:08:13,000
upon their respective types.

107
00:08:13,000 --> 00:08:19,000
For example, all the web processes responsible for handling the Http requests.

108
00:08:19,000 --> 00:08:25,000
And just like web processes, we also have worker processes that execute some scheduled background jobs.

109
00:08:25,000 --> 00:08:31,000
So by classifying all these processes and optimizing their concurrency, applications can effectively

110
00:08:31,000 --> 00:08:39,000
scale and handle increased workloads without having this concurrency ability inside your application

111
00:08:39,000 --> 00:08:42,000
and inside your programming language that you are going to use,

112
00:08:42,000 --> 00:08:43,000
Your cloud

113
00:08:43,000 --> 00:08:45,000
Native applications or microservices.

114
00:08:45,000 --> 00:08:47,000
They are not going to be easily scaled.

115
00:08:47,000 --> 00:08:48,000
I hope this is clear.

116
00:08:48,000 --> 00:08:55,000
Now let's move on to the next principle or guideline that we have, which is telemetry. Inside monolithic

117
00:08:55,000 --> 00:08:55,000
application

118
00:08:55,000 --> 00:09:01,000
we will have very limited number of applications, like 1 or 2 monitoring them, understanding their

119
00:09:01,000 --> 00:09:02,000
logs, metrics,

120
00:09:02,000 --> 00:09:08,000
performance related information is very easy because you have to monitor only one server or one application

121
00:09:08,000 --> 00:09:10,000
or two applications or two servers.

122
00:09:10,000 --> 00:09:17,000
Whereas with cloud native applications or microservices, you'll be having multiple containers running,

123
00:09:17,000 --> 00:09:23,000
multiple services running, multiple servers will be running inside your organization.

124
00:09:23,000 --> 00:09:28,000
So how are you going to monitor them. For the same we have a concept called observability.

125
00:09:28,000 --> 00:09:33,000
So these observability is a fundamental characteristic of cloud native applications.

126
00:09:33,000 --> 00:09:40,000
Since we are going to have multiple applications inside the cloud it becomes essential to have access

127
00:09:40,000 --> 00:09:45,000
to the accurate and comprehensive data from each component of the system.

128
00:09:45,000 --> 00:09:50,000
If you have 100 different microservices, you should be able to access the accurate information and

129
00:09:50,000 --> 00:09:57,000
comprehensive information about all these microservices in a single place. So that it can enable remote

130
00:09:57,000 --> 00:10:00,000
monitoring of the systems behavior and and facilitate

131
00:10:00,000 --> 00:10:04,000
effective management, what kind of data we need for this effective management.

132
00:10:04,000 --> 00:10:10,000
Telemetry data such as logs, metrics, traces, health status and events.

133
00:10:10,000 --> 00:10:17,000
All this plays a very vital role in providing this visibility into your cloud Native applications.

134
00:10:17,000 --> 00:10:23,000
If you try to understand how this telemetry is derived in Kevin Hoffman's analogy, he emphasizes the

135
00:10:23,000 --> 00:10:28,000
significance of telemetry by comparing with the applications to the space probes.

136
00:10:28,000 --> 00:10:34,000
So he's trying to compare our cloud native applications or microservices to the space probes.

137
00:10:34,000 --> 00:10:40,000
Space probes are nothing but the satellites are the space rockets that we send into the space for

138
00:10:40,000 --> 00:10:44,000
research. Space organizations like NASA, Isro.

139
00:10:44,000 --> 00:10:50,000
They will use this telemetry data of the space probe to monitor and control remotely.

140
00:10:50,000 --> 00:10:56,000
The same concept applies to the cloud native applications as well. To effectively monitor and control

141
00:10:56,000 --> 00:11:03,000
applications remotely, we need various types of telemetry data, and these telemetry data are like

142
00:11:03,000 --> 00:11:10,000
detailed logs for troubleshooting metrics to measure performance, traces to understand request flows,

143
00:11:10,000 --> 00:11:17,000
health status to access system well-being and events to capture significant occurrences, by gathering

144
00:11:17,000 --> 00:11:24,000
and utilizing all these type of telemetry data, we can gain valuable insights about our applications

145
00:11:24,000 --> 00:11:30,000
and microservices and make informed decisions to manage them effectively from a remote location.

146
00:11:30,000 --> 00:11:37,000
We are going to talk in detail about what is this telemetry, how to gather all this telemetry information

147
00:11:37,000 --> 00:11:39,000
into a single place inside this course.

148
00:11:39,000 --> 00:11:40,000
So please be informed,

149
00:11:40,000 --> 00:11:44,000
in the upcoming sections, we are going to talk in detail about this telemetry.

150
00:11:44,000 --> 00:11:51,000
But on a high level, what this guideline is recommending is please make sure your applications are

151
00:11:51,000 --> 00:11:55,000
feeding all this telemetry information to a centralized component.

152
00:11:55,000 --> 00:12:01,000
And from that centralized component, we should be able to monitor and control their behavior.

153
00:12:01,000 --> 00:12:02,000
I hope this is clear.

154
00:12:02,000 --> 00:12:08,000
Now, moving on to the last guiding principle, which is authentication and authorization.

155
00:12:08,000 --> 00:12:13,000
So security is a very critical aspect of any software system.

156
00:12:13,000 --> 00:12:19,000
But many times we see that this security is not receiving necessary emphasis it deserves.

157
00:12:19,000 --> 00:12:26,000
So what this guiding principle is saying is, we need to follow a zero trust approach and we need to make

158
00:12:26,000 --> 00:12:33,000
sure every communication and every interaction within the system and within the microservice network

159
00:12:33,000 --> 00:12:37,000
or cloud native systems is happening by following the security standards.

160
00:12:37,000 --> 00:12:43,000
When you talk about security, there are many things involved apart from authentication and authorization,

161
00:12:43,000 --> 00:12:46,000
which is the responsibility of the developer.

162
00:12:46,000 --> 00:12:52,000
Apart from these authentication and authorization platforms team, they can follow Https protocol,

163
00:12:52,000 --> 00:12:56,000
they can have some SSL certificates, they can have some firewall protection.

164
00:12:56,000 --> 00:13:00,000
So all these standards also our operations team, they are going to follow.

165
00:13:00,000 --> 00:13:06,000
But from the development perspective, following these authentication and authorization is very important.

166
00:13:06,000 --> 00:13:13,000
So what is an authentication, authentication enable us to track and identify who is the user trying to

167
00:13:13,000 --> 00:13:19,000
access our application. Once the authentication is completed, like with the help of username and password,

168
00:13:19,000 --> 00:13:26,000
we can then proceed to evaluating their permissions and determine if they have necessary authorization

169
00:13:26,000 --> 00:13:28,000
to perform a specific action.

170
00:13:28,000 --> 00:13:34,000
So inside authentication will only check the identity of the end user, whereas inside the authorization

171
00:13:34,000 --> 00:13:40,000
that is going to happen after the authentication, we are going to validate if a specific end user have

172
00:13:40,000 --> 00:13:45,000
enough privileges to perform a specific action inside a application.

173
00:13:45,000 --> 00:13:51,000
So implementing these authentication and authorization is very important for cloud native applications

174
00:13:51,000 --> 00:13:52,000
and microservices.

175
00:13:52,000 --> 00:13:58,000
Inside this course there is a separate section focusing on the security and how to implement it inside

176
00:13:58,000 --> 00:13:59,000
the microservices.

177
00:13:59,000 --> 00:14:06,000
We are going to leverage the standards like OAuth 2.1 and OpenID Connect to enforce security inside

178
00:14:06,000 --> 00:14:07,000
our microservices

179
00:14:07,000 --> 00:14:14,000
in the coming sections. With this, we discussed all the 15 factor methodology, principles and guidelines.

180
00:14:14,000 --> 00:14:18,000
I'm assuming your super, super clear about all these principles.

181
00:14:18,000 --> 00:14:23,000
We will follow all these principles while building our microservices.

182
00:14:23,000 --> 00:14:27,000
Please also make sure whenever you are building microservice you are following all these guidelines

183
00:14:27,000 --> 00:14:28,000
and principles.

184
00:14:28,000 --> 00:14:35,000
Without these methodology principles, you can't call your application as a microservice or as an cloud

185
00:14:35,000 --> 00:14:36,000
native application.

186
00:14:36,000 --> 00:14:40,000
Many times you will be asked some questions about them inside the interview.

187
00:14:40,000 --> 00:14:45,000
Since I'm sharing all these slides with you, please have them as your reference and brush up these

188
00:14:45,000 --> 00:14:48,000
15 factor methodology whenever you are going for an interview.

189
00:14:48,000 --> 00:14:50,000
I hope this is super, super clear for you.

190
00:14:50,000 --> 00:14:54,000
Thank you and I'll catch you in a new section.

191
00:14:54,000 --> 00:14:54,000
Bye.

